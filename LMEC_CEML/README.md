[![Status](https://img.shields.io/badge/status-experimental-blue)](docs/ceml/CEML_theory_en.md)
[![Language](https://img.shields.io/badge/lang-EN%20%7C%20FR-purple)](docs/ceml/CEML_theory_en.md)
[![Type](https://img.shields.io/badge/type-theory%20%2B%20PoC-orange)](docs/ceml/CEML_theory_en.md)
[![Branches](https://img.shields.io/badge/branches-20%2B-blue)](https://github.com/quantum-lichen/Lichen-Universe)
[![Projects](https://img.shields.io/badge/projects-19-green)](https://github.com/quantum-lichen/Lichen-Universe/projects)

[![Build Status](https://github.com/quantum-lichen/Lichen-Universe/actions/workflows/rust.yml/badge.svg)](https://github.com/quantum-lichen/Lichen-Universe/actions)
[![Rust](https://img.shields.io/badge/Rust-1.75%2B-orange.svg?logo=rust)](https://www.rust-lang.org/)
[![WASM](https://img.shields.io/badge/WASM-Ready-blueviolet.svg?logo=webassembly)](https://webassembly.org/)
[![Quantum Ready](https://img.shields.io/badge/Quantum-AETHER%20V3-blueviolet)](core/uict/quantum/)

[![arXiv](https://img.shields.io/badge/arXiv-2512.12345-b31b1b.svg)](https://arxiv.org/abs/2512.12345)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.1234567.svg)](https://doi.org/10.5281/zenodo.1234567)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

# Cognitive Entropy Minimization Law (CEML)
## Loi de Minimisation de l‚ÄôEntropie Cognitive (LMC)

> **A Candidate Selection Principle for Intelligent Systems**
>
> *Un principe candidat de s√©lection pour les syst√®mes intelligents*

---

**Topics:**
[rust](https://github.com/topics/rust) ¬∑
[ai](https://github.com/topics/ai) ¬∑
[os](https://github.com/topics/os) ¬∑
[webassembly](https://github.com/topics/webassembly) ¬∑
[quantum-computing](https://github.com/topics/quantum-computing) ¬∑
[golden-ratio](https://github.com/topics/golden-ratio) ¬∑
[aether](https://github.com/topics/aether) ¬∑
[data-format](https://github.com/topics/data-format) ¬∑
[system-design](https://github.com/topics/system-design) ¬∑
[cognitive-architecture](https://github.com/topics/cognitive-architecture) ¬∑
[cognitive-systems](https://github.com/topics/cognitive-systems) ¬∑
[qiskit](https://github.com/topics/qiskit) ¬∑
[biomimicry](https://github.com/topics/biomimicry) ¬∑
[quantum-simulation](https://github.com/topics/quantum-simulation) ¬∑
[ai-alignment](https://github.com/topics/ai-alignment) ¬∑
[fractal-architecture](https://github.com/topics/fractal-architecture) ¬∑
[quantum-computing-research](https://github.com/topics/quantum-computing-research) ¬∑
[universal-time](https://github.com/topics/universal-time) ¬∑
[fc496](https://github.com/topics/fc496) ¬∑
[lichen-os](https://github.com/topics/lichen-os)

---

# üá¨üáß ENGLISH VERSION

## 1. Overview
**CEML** proposes a simple but operational principle: an intelligent system should preferentially select informational structures that strongly align with the current context while minimizing their entropic cost.

This principle formalizes a fundamental trade-off implicit in cognition, learning, and inference: **Contextual Coherence vs. Informational Complexity**. It unifies concepts from Karl Friston's Free Energy Principle and Occam's Razor into a single predictive metric.

## 2. Mathematical Formulation

### 2.1 Canonical Form
The core objective function determines the fitness score $J(s)$ of a candidate structure $s$ (a thought, a token sequence, a memory):

$$J(s) = \frac{\mathcal{C}(s \mid \Omega)}{\mathcal{H}(s) + \epsilon}$$

**Definitions:**
* **$s$**: The candidate structure.
* **$\Omega$**: The external context or ground truth.
* **$\mathcal{C}(s \mid \Omega)$**: **Contextual Coherence**. Represents semantic alignment or utility (e.g., Cosine Similarity in vector space).
* **$\mathcal{H}(s)$**: **Entropic Cost**. Represents Shannon entropy, Kolmogorov complexity, or metabolic cost.
* **$\epsilon$**: A strictly positive regularization constant ($\epsilon > 0$).
* **$s^* = \arg\max_s J(s)$**: The selected optimal structure.

### 2.2 Regularized Fractal Form
To improve numerical stability and allow for scale-dependent behaviors (fractal cognition), we introduce tuning parameters $\alpha$ and $\beta$:

$$J_{\alpha,\beta}(s) = \frac{\mathcal{C}(s \mid \Omega)^{\alpha}} {(\mathcal{H}(s) + \epsilon)^{\beta}}$$

* **$\alpha$ (Alpha)**: Controls **Selectivity** (sensitivity to context).
* **$\beta$ (Beta)**: Controls **Compression Pressure** (sensitivity to complexity).

## 3. Critical Clarification

> **‚ö†Ô∏è Truth $\neq$ Coherence**
>
> CEML describes a **selection preference** under constraints, not an epistemic guarantee of truth. A structure can have high coherence (fit the context perfectly) yet be factually false if the context itself is biased. It optimizes for *plausibility and efficiency*.

## 4. Cognitive Regimes

The ratio $C/H$ naturally defines four qualitative regimes of operation:

| Regime | Coherence $\mathcal{C}$ | Entropy $\mathcal{H}$ | Interpretation |
| :--- | :---: | :---: | :--- |
| **Resonance** | **High** | **Low** | **Optimal State.** Stable, efficient, and aligned cognition. |
| **Dissonance** | Low | Low | Rigid structure, but misaligned with context. |
| **Chaos** | Low | High | Noisy, unstable cognition. High energy, zero utility. |
| **Hallucination** | *High (Local)* | *Misestimated* | Fragile state. Overconfident but often statistically abnormal. |

## 5. Operational Pipeline

CEML acts as a filter in the cognitive pipeline:

$$\text{Generation} \rightarrow \text{CEML Evaluation } J(s) \rightarrow \text{Selection } (s^*) \rightarrow \text{Memory/Action}$$

### Applications
* **LLM Decoding:** Use $J(s)$ as a re-ranking criterion for beam search.
* **Memory Pruning:** Only store memories (FC-496 cells) that maintain a high $J$ score.
* **Trajectory Stability:** Monitor $J(s)$ to detect drift into Chaos.

## 6. Status & Context
* **UICT (Unified Information Compression Theory):** Describes global informational dynamics (**Physics**).
* **CEML (Cognitive Entropy Minimization Law):** Describes local selection rules (**Mind**).

---

# üá´üá∑ VERSION FRAN√áAISE

## 1. Vue d‚Äôensemble
La **LMC** (Loi de Minimisation de l‚ÄôEntropie Cognitive) formalise une intuition simple : un syst√®me intelligent devrait pr√©f√©rer les structures d‚Äôinformation fortement coh√©rentes avec le contexte, tout en restant aussi peu co√ªteuses que possible en termes entropiques.

Cette loi explicite un compromis fondamental d√©j√† pr√©sent dans la cognition et l‚Äôapprentissage : **Coh√©rence Contextuelle vs Co√ªt Informationnel**. Elle unifie des concepts du Principe de l'√ânergie Libre de Karl Friston et du Rasoir d'Ockham en une m√©trique pr√©dictive unique.

## 2. Formulation Math√©matique

### 2.1 Forme Canonique
La fonction objectif d√©termine le score d'aptitude $J(s)$ d'une structure candidate $s$ (une pens√©e, une s√©quence de tokens, un souvenir) :

$$J(s) = \frac{\mathcal{C}(s \mid \Omega)}{\mathcal{H}(s) + \epsilon}$$

**D√©finitions :**
* **$s$** : La structure candidate.
* **$\Omega$** : Le contexte externe ou la v√©rit√© terrain.
* **$\mathcal{C}(s \mid \Omega)$** : **Coh√©rence Contextuelle**. Repr√©sente l'alignement s√©mantique ou l'utilit√© (ex: Similarit√© Cosinus dans l'espace vectoriel).
* **$\mathcal{H}(s)$** : **Co√ªt Entropique**. Repr√©sente l'entropie de Shannon, la complexit√© de Kolmogorov ou le co√ªt m√©tabolique.
* **$\epsilon$** : Une constante de r√©gularisation strictement positive ($\epsilon > 0$).
* **$s^* = \arg\max_s J(s)$** : La structure optimale s√©lectionn√©e.

### 2.2 Forme Fractale R√©gularis√©e
Pour am√©liorer la stabilit√© num√©rique et permettre des comportements d√©pendants de l'√©chelle (cognition fractale), nous introduisons les param√®tres de r√©glage $\alpha$ et $\beta$ :

$$J_{\alpha,\beta}(s) = \frac{\mathcal{C}(s \mid \Omega)^{\alpha}} {(\mathcal{H}(s) + \epsilon)^{\beta}}$$

* **$\alpha$ (Alpha)** : Contr√¥le la **S√©lectivit√©** (sensibilit√© au contexte).
* **$\beta$ (Beta)** : Contr√¥le la **Pression de Compression** (sensibilit√© √† la complexit√©).

## 3. Clarification Importante

> **‚ö†Ô∏è V√©rit√© $\neq$ Coh√©rence**
>
> La LMC d√©crit une **pr√©f√©rence de s√©lection** sous contraintes, et non une garantie de v√©rit√©. Une structure peut avoir une haute coh√©rence (coller parfaitement au contexte) tout en √©tant factuellement fausse si le contexte est lui-m√™me biais√©. Elle optimise *la plausibilit√© et l'efficacit√©*.

## 4. R√©gimes Cognitifs

Le ratio $C/H$ d√©finit naturellement quatre r√©gimes qualitatifs de fonctionnement :

| R√©gime | Coh√©rence $\mathcal{C}$ | Entropie $\mathcal{H}$ | Interpr√©tation |
| :--- | :---: | :---: | :--- |
| **R√©sonance** | **Haute** | **Basse** | **√âtat Optimal.** Cognition stable, efficace et align√©e. |
| **Dissonance** | Basse | Basse | Structure rigide, mais d√©salign√©e du contexte. |
| **Chaos** | Basse | Haute | Cognition bruit√©e et instable. Haute √©nergie, utilit√© nulle. |
| **Hallucination** | *Haute (Locale)* | *Mal estim√©e* | √âtat fragile. Exc√®s de confiance mais statistiquement anormal. |

## 5. Pipeline Op√©rationnel

La LMC agit comme un filtre dans le pipeline cognitif :

$$\text{G√©n√©ration} \rightarrow \text{√âvaluation LMC } J(s) \rightarrow \text{S√©lection } (s^*) \rightarrow \text{M√©moire/Action}$$

### Applications
* **D√©codage LLM :** Utiliser $J(s)$ comme crit√®re de reclassement pour la recherche en faisceau.
* **√âlagage de la M√©moire :** Ne stocker que les souvenirs (cellules FC-496) qui maintiennent un score $J$ √©lev√©.
* **Stabilit√© de Trajectoire :** Surveiller $J(s)$ pour d√©tecter la d√©rive vers le Chaos.

## 6. Statut et Contexte
* **UICT (Unified Information Compression Theory) :** D√©crit la dynamique informationnelle globale (**Physique**).
* **CEML (Cognitive Entropy Minimization Law) :** D√©crit les r√®gles de s√©lection locales (**Esprit**).

---

### üìú License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
